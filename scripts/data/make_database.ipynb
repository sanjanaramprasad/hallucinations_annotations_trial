{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_dir = '/work/frink/ramprasad.sa/factuality_metrics/datasets'\n",
    "# filename = 'aggrefact_llm.csv'\n",
    "# df = pd.read_csv(f'{read_dir}/{filename}')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(data_dir,\n",
    "              genaudit_file,\n",
    "             annotated_file,\n",
    "             add_files):\n",
    "    df_genaudit = pd.read_csv(f'{data_dir}/{genaudit_file}')\n",
    "    df_annotated = pd.read_csv(f'{data_dir}/{annotated_file}')\n",
    "    df_summaries = df_genaudit[df_genaudit['id'].isin(df_annotated['docid'])]\n",
    "\n",
    "    added_dfs = [df_summaries]\n",
    "    for add_file in add_files:\n",
    "        df_add = pd.read_csv(f'{data_dir}/{add_file}')\n",
    "        added_dfs += [df_add]\n",
    "    return pd.concat(added_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_genaudit = pd.read_csv('/Users/srampras/hallucinations_annotations/scripts/data/genaudit_annotations.csv')\n",
    "df_annotated = pd.read_csv('/Users/srampras/hallucinations_annotations/scripts/data/test_ann_db_dump_07_12_2024.csv')\n",
    "# df_genaudit = df_summaries[df_summaries['id'].isin(df_annotated['docid'])]\n",
    "# df_summaries.head()[:2]\n",
    "\n",
    "data_dir = '/Users/srampras/hallucinations_annotations/scripts/data'\n",
    "genaudit_file = 'genaudit_annotations.csv'\n",
    "annotated_file = 'test_ann_db_dump_07_12_2024.csv'\n",
    "# add_files = ['llama3_8b_summaries.csv']\n",
    "add_files = []\n",
    "\n",
    "df_summaries = make_data(data_dir = data_dir,\n",
    "                        genaudit_file = genaudit_file,\n",
    "                        annotated_file = annotated_file,\n",
    "                        add_files = add_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_genaudit)\n",
    "# # shortlisted_ids = ['40110402', '39664212', 'REDDIT-9', 'REDDIT-80', 'ACIBENCH-D2N126', 'ACIBENCH-D2N124', 'ACIBENCH-D2N123', 'ACIBENCH-D2N094', 'ACIBENCH-D2N088', 'ACIBENCH-D2N090']\n",
    "# shortlisted_ids = ['ACIBENCH-D2N106', 'REDDIT-83', '35441162', 'REDDIT-54', 'D2N108' ]\n",
    "# df_genaudit_sample = []\n",
    "# for sid in shortlisted_ids:\n",
    "#     sids = [each for each in df_genaudit['id'] if sid in each]\n",
    "#     sids = [each for each in sids if 'llama70b' in each or 'gpt4' in each]\n",
    "#     df_genaudit_sample += [df_genaudit[df_genaudit['id'].isin(sids)]]\n",
    "\n",
    "# df_genaudit_sample = pd.concat(df_genaudit_sample)\n",
    "# df_genaudit_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "   database=\"d65103c5a2kbgs\", \n",
    "    user='u16ifm924gr2m8', \n",
    "    password='pe4029f0ba1fbaafd034f4dbf17f703bf9a5d6c8420f07719f5db4054c9d4da40', \n",
    "    host='c1gvrf2q90nbcq.cluster-czrs8kj4isg7.us-east-1.rds.amazonaws.com', \n",
    "    port = '5432'\n",
    "    \n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cursor.execute(\"\"\"DELETE FROM label WHERE user_id='rachel_usher'\"\"\")\n",
    "# # cursor.fetchall()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully........\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sql_drop = '''DROP TABLE IF EXISTS model_summaries;'''\n",
    "\n",
    "sql = '''CREATE TABLE model_summaries (\n",
    "    uuid uuid DEFAULT gen_random_uuid() PRIMARY KEY, \n",
    "    docid TEXT NOT NULL ,\n",
    "    source TEXT,\n",
    "    summary TEXT NOT NULL,\n",
    "    model TEXT NOT NULL, \n",
    "    benchmark_dataset_name TEXT,\n",
    "    origin TEXT\n",
    ");'''\n",
    "\n",
    "#Creating a database\n",
    "cursor.execute(sql_drop)\n",
    "cursor.execute(sql)\n",
    "print(\"Table created successfully........\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = conn.cursor()\n",
    "# sql_drop = '''DROP TABLE IF EXISTS label;'''\n",
    "# # d SERIAL PRIMARY KEY,\n",
    "# #     source_id INT NOT NULL,\n",
    "# #     start_pos INT NOT NULL,\n",
    "# #     end_pos INT NOT NULL,\n",
    "# #     text TEXT NOT NULL,\n",
    "# #     category VARCHAR(50) NOT NULL,\n",
    "# #     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "\n",
    "\n",
    "# create_table_label_str = '''CREATE TABLE label (\n",
    "#     uuid uuid DEFAULT gen_random_uuid() PRIMARY KEY, \n",
    "#     user_id TEXT NOT NULL,\n",
    "#     docid TEXT NOT NULL,\n",
    "#     source TEXT NOT NULL,\n",
    "#     summary TEXT NOT NULL,\n",
    "#     model TEXT NOT NULL,\n",
    "#     benchmark_dataset_name TEXT,\n",
    "#     origin TEXT,\n",
    "#     nonfactual_span TEXT,\n",
    "#     error_type TEXT,\n",
    "#     mistake_severity TEXT,\n",
    "#     inference_likelihood TEXT,\n",
    "#     inference_knowledge TEXT,\n",
    "#     attempt_number INT\n",
    "# );'''\n",
    "\n",
    "# cursor.execute(sql_drop)\n",
    "# cursor.execute(create_table_label_str)\n",
    "# print(\"Table created successfully........\")\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully........\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "sql_drop = '''DROP TABLE IF EXISTS modified_label;'''\n",
    "# d SERIAL PRIMARY KEY,\n",
    "#     source_id INT NOT NULL,\n",
    "#     start_pos INT NOT NULL,\n",
    "#     end_pos INT NOT NULL,\n",
    "#     text TEXT NOT NULL,\n",
    "#     category VARCHAR(50) NOT NULL,\n",
    "#     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "\n",
    "\n",
    "create_table_label_str = '''CREATE TABLE modified_label (\n",
    "    uuid uuid DEFAULT gen_random_uuid() PRIMARY KEY, \n",
    "    user_id TEXT NOT NULL,\n",
    "    docid TEXT NOT NULL,\n",
    "    source TEXT NOT NULL,\n",
    "    summary TEXT NOT NULL,\n",
    "    model TEXT NOT NULL,\n",
    "    benchmark_dataset_name TEXT,\n",
    "    origin TEXT,\n",
    "    nonfactual_span TEXT,\n",
    "    error_type TEXT,\n",
    "    mistake_severity TEXT,\n",
    "    inference_likelihood TEXT,\n",
    "    inference_knowledge TEXT,\n",
    "    inference_severity TEXT,\n",
    "    attempt_number INT\n",
    ");'''\n",
    "\n",
    "cursor.execute(sql_drop)\n",
    "cursor.execute(create_table_label_str)\n",
    "print(\"Table created successfully........\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before adding 0\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"SELECT * from modified_label\"\"\")\n",
    "print('Size before adding' , len(cursor.fetchall()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before adding 0\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "cursor.execute(\"\"\"SELECT * from model_summaries\"\"\")\n",
    "print('Size before adding' , len(cursor.fetchall()))\n",
    "\n",
    "# df_genaudit = df_genaudit[df_genaudit['faithful'] == 1]\n",
    "df_summaries = df_summaries[~df_summaries['summary'].isnull()]\n",
    "df_summaries = df_summaries[~df_summaries['source'].isnull()]\n",
    "for idx, row in df_summaries.iterrows():\n",
    "    # print(row)\n",
    "    docid = row['id']\n",
    "    source = row['source']\n",
    "    summary = row['summary']\n",
    "    model = row['model']\n",
    "    origin = row['origin']\n",
    "    benchmark_dataset_name = row['benchmark_dataset_name']\n",
    "    if 'summary' in df_summaries.keys(): \n",
    "        # and row['DocID'] in filter_ids:\n",
    "        summary = row['summary']\n",
    "        summary_uuid_generic = f'{docid}_{benchmark_dataset_name}_{origin}_{model}'\n",
    "        summary = re.sub( \"'\", r\"''\", summary)\n",
    "        source = re.sub( \"'\", r\"''\", source)\n",
    "        value_str = f\"\"\"'{docid}', '{source}', '{summary}', '{model}', '{benchmark_dataset_name}', '{origin}'\"\"\"\n",
    "        # print(re.findall(r\"\\'(\\w+)\\'\", dialogue))\n",
    "        cursor.execute(f\"\"\"INSERT INTO model_summaries(docid, source, summary, model, benchmark_dataset_name, origin) VALUES ({value_str})\"\"\",\n",
    "                                                        )\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size after adding 39\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"SELECT * from model_summaries\"\"\")\n",
    "\n",
    "print('Size after adding' , len(cursor.fetchall()))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InFailedSqlTransaction",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInFailedSqlTransaction\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mSELECT * from modified_label\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m cursor\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "\u001b[0;31mInFailedSqlTransaction\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"SELECT * from modified_label\"\"\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = conn.cursor()\n",
    "# cursor.execute(\"\"\"DELETE FROM label WHERE user_id='rachel_usher'\"\"\")\n",
    "# # cursor.fetchall()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
